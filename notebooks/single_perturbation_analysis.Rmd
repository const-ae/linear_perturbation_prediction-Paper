---
title: "R Notebook"
---


```{r}
library(tidyverse)
library(glue)
source("util.R")
```



```{r}
pert_res <- bind_rows(readRDS("../benchmark/output/single_perturbation_results_predictions.RDS"))
parameters <- readRDS(file.path("../benchmark/output/single_perturbation_results_parameters.RDS")) %>%
  map(\(p) tibble(id = p$id, name = p$name, parameters = as_tibble(p$parameters), 
                  train = names(p$test_train_labels), perturbation = p$test_train_labels)) %>%
  bind_rows() %>%
  unnest(perturbation) %>%
  unpack(parameters)
```



```{r, paged.print=FALSE}
res <- pert_res %>%
  mutate(perturbation_split = str_split(perturbation, pattern = "[+_]", n = 2)) %>%
  mutate(perturbation_split = map(perturbation_split, \(x) {
    if(all(x == "ctrl" | x == "")) "ctrl" 
    else if(length(x) == 2) x
    else c(x, "ctrl")
  })) %>%
  mutate(perturbation = map_chr(perturbation_split, paste0, collapse = "+")) %>%
  tidylog::left_join(parameters, by = c("id", "name", "perturbation")) %>%  # Matches most of x. Non matches are from scGPT and are not in training
  tidylog::filter(! is.na(train)) %>%
  separate(name, sep = "-", into = c("dataset_name2", "seed2", "method"), convert = TRUE) %>%
  tidylog::filter(dataset_name2 == dataset_name | seed2 == seed) %>%
  dplyr::select(-c(dataset_name2, seed2))

res
```


```{r, paged.print=FALSE}
res %>%
  filter(method == "ground_truth" & seed == 1) %>%
  mutate(n_pert = lengths(map(perturbation_split, \(x) setdiff(x, "ctrl")))) %>%
  dplyr::count(dataset_name, n_pert) 

res %>%
  filter(method == "ground_truth" & seed == 1) %>%
  mutate(n_pert = lengths(map(perturbation_split, \(x) setdiff(x, "ctrl")))) %>%
  filter(n_pert == 1) %>%
  dplyr::count(dataset_name, train) 
```


```{r, paged.print=FALSE}
long2matrix <- function(x, rows, cols, values, ...){
  df_mat <- x |>
    transmute({{rows}}, {{cols}}, {{values}}) |>
    pivot_wider(id_cols = {{rows}}, names_from = {{cols}}, values_from = {{values}}, ...) 
  mat<- as.matrix(df_mat[,-1])
  rownames(mat) <- df_mat[[1]]
  mat
}

res |>
  filter(seed == 1) |>
  mutate(present = map_lgl(prediction, \(x) ! is.na(x[1]))) |>
  group_by(dataset_name) %>%
  group_map(\(data, key){
    mat <- long2matrix(data, rows = method, cols = perturbation, values = present, values_fn = \(x) x * 1.0) 
    mat[is.na(mat)] <- 0
    ComplexHeatmap::pheatmap(mat, main = key[[1]][1], breaks = c(0,1), color = c("lightgrey", "darkred"),
                             show_row_dend = FALSE, show_column_dend = FALSE, show_colnames = FALSE, legend = FALSE)
  })

```


```{r, paged.print=FALSE}
valid_perts <- res %>%
  filter(map_lgl(prediction, \(x) !is.na(x[1]))) %>%
  dplyr::select(dataset_name, seed, method, perturbation) %>%
  summarize(n = n(), .by = c(dataset_name,seed, perturbation)) %>%
  filter(n == max(n), .by = c(dataset_name, seed)) %>%
  dplyr::select(-n)
``` 


```{r, paged.print=FALSE}
baselines <- res %>%
  filter(method == "ground_truth" & perturbation == "ctrl") %>%
  dplyr::select(baseline = prediction, dataset_name, seed) 
```


```{r, paged.print=FALSE}
expr_rank_df <- res %>%
  filter(method == "ground_truth" & perturbation == "ctrl") %>%
  dplyr::select(dataset_name, seed, observed = prediction) %>%
  mutate(gene_name = map(observed, names)) %>%
  unnest(c(gene_name, observed)) %>%
  mutate(expr_rank = rank(desc(observed), ties = "first"), .by = c(seed, dataset_name)) %>%
  dplyr::select(dataset_name, seed, gene_name, expr_rank)
  
de_rank_df <- res %>%
  filter(method == "ground_truth") %>% 
  dplyr::select(dataset_name, seed, perturbation, observed = prediction) %>%
  left_join(baselines, by = c("dataset_name", "seed")) %>%
  unnest_named_lists(c(observed, baseline), names_to = "gene_name") %>%
  mutate(de = abs(observed - baseline)) %>%
  mutate(de_rank = rank(desc(de), ties = "first"), .by = c(seed, dataset_name, perturbation)) %>%
  dplyr::select(dataset_name, seed, perturbation, gene_name, de_rank)
```

```{r}
mem.maxVSize(vsize = Inf)
```


```{r, paged.print=FALSE}
contr_res <- tidylog::full_join(filter(res, method != "ground_truth"),
                                filter(res, method == "ground_truth") %>% 
                                  dplyr::select(dataset_name, seed, perturbation, observed = prediction),
           by = c("dataset_name", "seed", "perturbation"))

# Takes 7 min
system.time({
  full_long_df <- contr_res %>%
    tidylog::left_join(baselines, by = c("dataset_name", "seed")) %>%
    tidylog::inner_join(valid_perts, by = c("perturbation", "dataset_name", "seed")) %>%
    dplyr::select(dataset_name, seed, method, perturbation, train, prediction, baseline, observed) %>%
    unnest_named_lists(c(prediction, baseline, observed), names_to = "gene_name")
})

res_metrics <- full_long_df %>%
  inner_join(expr_rank_df %>% dplyr::select(dataset_name, seed, gene_name, expr_rank) %>% 
               filter(expr_rank <= 1000), by = c("dataset_name", "seed", "gene_name")) %>%
  filter(! if_any(c(prediction, baseline, observed), is.na)) %>%
  summarize(r2 = cor(prediction, observed),
         r2_delta = cor(prediction - baseline, observed - baseline),
         l2 =sqrt(sum((prediction - observed)^2)),
         .by = c(dataset_name, seed, method, perturbation, train))

res_metrics
```




```{r, paged.print=FALSE}
method_labels <- c("gears" = "GEARS", "scgpt" = "scGPT",
                   "scfoundation" = "scFoundation", "lpm_selftrained" = "lpm_selftrained",
                   "lpm_randomPertEmb" = "lpm_randomPertEmb", "lpm_randomGeneEmb" = "lpm_randomGeneEmb",
                   "lpm_scgptGeneEmb" = "lpm_scgptGeneEmb", "lpm_scFoundationGeneEmb" = "lpm_scFoundationGeneEmb",
                   "lpm_gearsPertEmb" = "lpm_gearsPertEmb", "lpm_k562PertEmb" = "lpm_k562PertEmb",
                   "lpm_rpe1PertEmb" = "lpm_rpe1PertEmb")
dataset_labels <- c("adamson" = "Adamson", "replogle_k562_essential" = "Replogle K562", "replogle_rpe1_essential" = "Replogle RPE1")

main_pl_data <- res_metrics %>%
  filter(train %in% c("test", "val")) %>%
  mutate(method = factor(method, levels = names(method_labels))) %>%
  mutate(dataset_name = factor(dataset_name, levels = names(dataset_labels))) 

main_pl_pearson <- main_pl_data %>%
  ggplot(aes(x = method, y = r2_delta)) +
    geom_hline(yintercept = 0, color = "black", linewidth = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.1, color =  "#444444", alpha = 0.6) +
    stat_summary(geom = "crossbar", fun = mean, color = "red") +
    facet_wrap(vars(dataset_name), scales = "free_x", labeller = as_labeller(dataset_labels), nrow = 1) +
    scale_x_discrete(labels = method_labels, drop=FALSE) +
    scale_y_continuous(limits = c(-0.25, 1), expand = expansion(add = 0)) +
    guides(x = guide_axis(angle = 90)) +
    labs(y = "Pearson delta") +
    theme(axis.title.x = element_blank(),
          panel.grid.major.y = element_line(color = "lightgrey", linewidth = 0.1),
          panel.grid.minor.y = element_line(color = "lightgrey", linewidth = 0.1),
          panel.spacing.x = unit(3, "mm"))

main_pl_l2 <- main_pl_data %>%
  mutate(highlight = (perturbation %in% c("CEBPE+KLF1", "TGFBR2+ETS2") & method == "additive_model")) %>%
  ggplot(aes(x = method, y = l2)) +
    geom_hline(yintercept = 0, color = "black", linewidth = 0.2) +
    ggbeeswarm::geom_quasirandom(aes(color = highlight), size = 0.1) +
    # ggbeeswarm::geom_quasirandom(size = 0.1, color =  "#444444", alpha = 0.6) +
    stat_summary(geom = "crossbar", fun = mean, color = "red") +
    facet_wrap(vars(dataset_name), scales = "free_x") + #, labeller = as_labeller(dataset_labels), nrow = 1) +
    scale_x_discrete(labels = method_labels, drop=FALSE) +
    scale_y_continuous(limits = c(0, NA), expand = expansion(add = c(0, 0.5))) +
    scale_color_manual(values = c("TRUE" = "black", "FALSE" = alpha("#444444", 0.6))) +
    guides(x = guide_axis(angle = 90), color = "none") +
    labs(y = "Prediction error ($L_2$)") +
    theme(axis.title.x = element_blank(),
          panel.grid.major.y = element_line(color = "lightgrey", linewidth = 0.1),
          panel.grid.minor.y = element_line(color = "lightgrey", linewidth = 0.1),
          panel.spacing.x = unit(3, "mm"))

main_pl_pearson
main_pl_l2
```


Head line figure:

```{r, paged.print=FALSE}
headline_labels <- c("gears" = "GEARS", "scgpt" = "scGPT", "scfoundation" = "scFoundation",
                     "lpm_selftrained" = "LM with $\\matr{G}$,$\\matr{P}$\nfrom training",
                     "lpm_k562PertEmb" = "LM with $\\matr{P}$ from\nK562 Replogle",
                     "lpm_rpe1PertEmb" = "LM with $\\matr{P}$ from\nRPE1 Replogle",
                     "lpm_pertEmb" = "LM with $\\matr{P}$\nfrom Replogle")

main_pl <- main_pl_data %>%
  filter(method %in% c("gears", "scgpt", "scfoundation", "lpm_selftrained") |
           (dataset_name %in% c("adamson", "replogle_rpe1_essential") & method == "lpm_k562PertEmb") |
           (dataset_name %in% c("replogle_k562_essential") & method == "lpm_rpe1PertEmb")) %>%
  # mutate(method = if_else(str_detect(method, "lpm_((k562)|(rpe1))PertEmb"), "lpm_pertEmb", method)) %>%
  bind_rows(tibble(dataset_name = names(dataset_labels), method = "scfoundation", l2  = 5)) %>%
  mutate(method = factor(method, levels = names(headline_labels))) %>%
  ggplot(aes(x = method, y = l2)) +
    geom_hline(yintercept = 0, color = "black", linewidth = 0.2) +
    ggrastr::rasterize(ggbeeswarm::geom_quasirandom(aes(alpha = method == "scfoundation"),
                                                    color = "#444444", size = 0.6, stroke = 0, width = 0.3), dpi=600) +
    stat_summary(data = . %>% filter(method != "scfoundation"), geom = "crossbar", fun = mean, color = "red") +
    facet_wrap(vars(dataset_name), scales = "free_x", labeller = as_labeller(dataset_labels), nrow = 1) +
    scale_x_discrete(labels = headline_labels, drop=TRUE) +
    scale_y_continuous(limits = c(0, NA), expand = expansion(add = c(0, 0.5))) +
    scale_alpha_manual(values = c("TRUE" = 0, "FALSE" = 0.6)) +
    guides(x = guide_axis(angle = 90), color = "none", alpha = "none") +
    labs(y = "Prediction error ($L_2$)") +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_text(lineheight = 0.7),
          panel.grid.major.y = element_line(color = "lightgrey", linewidth = 0.1),
          panel.grid.minor.y = element_line(color = "lightgrey", linewidth = 0.1),
          panel.spacing.x = unit(5, "mm"))

pearson_delta_plot <- main_pl_data %>%
  filter(method %in% c("gears", "scgpt", "scfoundation", "lpm_selftrained") |
           (dataset_name %in% c("adamson", "replogle_rpe1_essential") & method == "lpm_k562PertEmb") |
           (dataset_name %in% c("replogle_k562_essential") & method == "lpm_rpe1PertEmb")) %>%
  bind_rows(tibble(dataset_name = names(dataset_labels), method = "scfoundation", r2_delta  = 0.5)) %>%
  mutate(method = factor(method, levels = names(headline_labels))) %>%
  ggplot(aes(x = method, y = r2_delta)) +
    geom_hline(yintercept = 0, color = "black", linewidth = 0.2) +
    ggrastr::rasterize(ggbeeswarm::geom_quasirandom(aes(alpha = method == "scfoundation"),
                                                    color = "#444444", size = 0.6, stroke = 0, width = 0.3), dpi=600) +
    stat_summary(data = . %>% filter(method != "scfoundation"), geom = "crossbar", fun = mean, color = "red") +
    facet_wrap(vars(dataset_name), scales = "free_x", labeller = as_labeller(dataset_labels), nrow = 1) +
    scale_x_discrete(labels = headline_labels, drop=TRUE) +
    # scale_y_continuous(limits = c(0, NA), expand = expansion(add = c(0, 0.5))) +
    scale_alpha_manual(values = c("TRUE" = 0, "FALSE" = 0.6)) +
    guides(x = guide_axis(angle = 90), color = "none", alpha = "none") +
    labs(y = "Pearson Delta") +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_text(lineheight = 0.7),
          panel.grid.major.y = element_line(color = "lightgrey", linewidth = 0.1),
          panel.grid.minor.y = element_line(color = "lightgrey", linewidth = 0.1),
          panel.spacing.x = unit(5, "mm"))


main_pl
pearson_delta_plot
```

```{r, paged.print=FALSE}
main_pl_data %>%
  filter(method == "gears") %>%
  count(dataset_name)
```



```{r}
plot_assemble(
  add_text("(A) Single perturbation prediction correlation", 
           x = 2.7, y = 1, fontsize = font_size, vjust = 1, fontface = "bold"),
  add_plot(pearson_delta_plot, x = 3, y = 2, width = 110, height = 47.5),
  
  
  width = 170, height = 50, units = "mm", show_grid_lines = FALSE,
  latex_support = TRUE, filename = "../plots/suppl-pearson_delta_performance_single_pert.pdf"
)
```


```{r, paged.print=FALSE}
sel_ranks <- c(seq(1, 100, by = 1), seq(101, 1000, by = 10), seq(1001, 19264, by = 100))

strat_data_expr_rank <- full_long_df %>%
  filter(train != "train") %>%
  left_join(expr_rank_df %>% distinct(gene_name, .keep_all=TRUE) %>%
              dplyr::select(dataset_name, seed, gene_name, rank = expr_rank),
            by = c("dataset_name", "seed", "gene_name")) %>%
  arrange(rank) %>%
  mutate(dist = sqrt(cumsum((prediction - observed)^2)),
         .by = c(dataset_name, seed, method, perturbation))  %>% 
  filter(rank %in% sel_ranks)

strat_colors <- c("gears" = "#7CAE00", "scgpt" = "#C77CFF",
                  "lpm_selftrained" = colorspace::lighten("#F8766D", 0.2),
                  "lpm_pertEmb" = colorspace::darken("#F8766D", 0.2))

strat_plot <- strat_data_expr_rank %>%
  filter(method %in% c("gears", "scgpt", "scfoundation", "lpm_selftrained") |
           (dataset_name %in% c("adamson", "replogle_rpe1_essential") & method == "lpm_k562PertEmb") |
           (dataset_name %in% c("replogle_k562_essential") & method == "lpm_rpe1PertEmb")) %>%
  mutate(method = if_else(str_detect(method, "lpm_((k562)|(rpe1))PertEmb"), "lpm_pertEmb", method)) %>%
  mutate(method = factor(method, levels = names(headline_labels))) %>%
  summarize(dist_mean = mean(dist),
            dist_se = sd(dist) / sqrt(first(rank)),
            .by = c(method, dataset_name, seed, rank)) %>%
  ggplot(aes(x = rank, y = dist_mean)) +
    ggrastr::rasterize(geom_line(aes(color = method), linewidth = 0.3), dpi = 600) +
    geom_vline(data = tibble(rank = 1000), aes(xintercept = rank),linewidth = 0.4, linetype = "dashed", color = "grey") +
    scale_x_log10() +
    scale_y_continuous(limits = c(0, NA), expand = expansion(add = c(0, 0.5))) +
    scale_color_manual(values = strat_colors, labels = str_replace(headline_labels, "\n", " ") |>
                         magrittr::set_names(names(headline_labels)), drop=TRUE) +
    facet_wrap(vars(dataset_name), , labeller = as_labeller(dataset_labels), nrow = 1) +
    labs(x = "Number of genes (log-scale)", y = "Mean prediction error", color = "") +
    guides(color = guide_legend(override.aes = list(linewidth = 1.6),  nrow = 2)) +
    theme(legend.position = "bottom", legend.key.spacing.y = unit(0, "mm"),
          legend.key.height = unit(2, "mm"))

strat_plot
```


```{r, paged.print=FALSE}
bootstrap <- function(data, FUN, n_iterations = 1000, map_fun = purrr::map){
  n <- length(data)
  tibble(bootstrap_iteration = seq_len(n_iterations),
         value = map_fun(seq_len(n_iterations), \(idx){
            sel <- sample.int(n, size = n, replace = TRUE)
            FUN(data[sel])
          }))
}

contrast_colors <- c("#d95f02", "#7570b3")


comparison_plot_scgpt <- res_metrics %>%
  filter(method %in% c("scgpt", "lpm_scgptGeneEmb")) %>%
  filter(train != "train") %>%
  summarize(l2 = {
    tmp <- bootstrap(l2, mean, map_fun = map_dbl)
    tibble(mean = mean(tmp$value), se = sd(tmp$value))
  }, .by = c(method, dataset_name)) %>%
  mutate(method = factor(method, c("scgpt", "lpm_scgptGeneEmb"))) %>%
  ggplot(aes(x = dataset_name, y = l2$mean)) +
    geom_pointrange(aes(color = method, ymin = l2$mean - l2$se, ymax = l2$mean + l2$se),
                    position = position_dodge(width = 0.4), fatten = 0.6, size = 0.8, show.legend = FALSE) +
    scale_x_discrete(labels = dataset_labels) +
    scale_y_continuous(limits = c(2.8, 6.8), breaks = c(3, 4, 5, 6)) +
    scale_color_manual(values = contrast_colors) +
    labs(y = "Prediction error ($L_2$)", 
         subtitle = paste0("\\textcolor{colorbrewerDarkOrange}{\\scalebox{1.3}{$\\bullet$}} scGPT vs.\n",
                           "\\textcolor{colorbrewerDarkPurple}{\\scalebox{1.3}{$\\bullet$}} LM with $\\matr{G}$ from scGPT")) +
    guides(x = guide_axis(angle = 90)) +
    theme(axis.title.x = element_blank(), plot.title.position = "plot")

comparison_plot_scfoundation <- res_metrics %>%
  filter(method %in% c("scgpt", "lpm_scFoundationGeneEmb")) %>%
  filter(train != "train") %>%
  summarize(l2 = {
    tmp <- bootstrap(l2, mean, map_fun = map_dbl)
    tibble(mean = mean(tmp$value), se = sd(tmp$value))
  }, .by = c(method, dataset_name)) %>%
  mutate(method = factor(method, c("scgpt", "lpm_scFoundationGeneEmb"))) %>%
  ggplot(aes(x = dataset_name, y = l2$mean)) +
    geom_pointrange(aes(color = method, ymin = l2$mean - l2$se, ymax = l2$mean + l2$se),
                    position = position_dodge(width = 0.4), fatten = 0.6, size = 0.8, show.legend = FALSE) +
    scale_x_discrete(labels = dataset_labels) +
    scale_y_continuous(limits = c(2.8, 6.8), breaks = c(3, 4, 5, 6)) +
    scale_color_manual(values = contrast_colors) +
    labs(y = "Prediction error ($L_2$)", 
         subtitle = paste0("\\textcolor{colorbrewerDarkOrange}{\\scalebox{1.3}{$\\bullet$}} scGPT vs.\n",
                           "\\textcolor{colorbrewerDarkPurple}{\\scalebox{1.3}{$\\bullet$}} LM with $\\matr{G}$ from scFoundation")) +
    guides(x = guide_axis(angle = 90)) +
    theme(axis.title.x = element_blank(), plot.title.position = "plot")

comparison_plot_gears <- res_metrics %>%
  filter(method %in% c("gears", "lpm_gearsPertEmb")) %>%
  filter(train != "train") %>%
  summarize(l2 = {
    tmp <- bootstrap(l2, mean, map_fun = map_dbl)
    tibble(mean = mean(tmp$value), se = sd(tmp$value))
  }, .by = c(method, dataset_name)) %>%
  mutate(method = factor(method, c("gears", "lpm_gearsPertEmb"))) %>%
  ggplot(aes(x = dataset_name, y = l2$mean)) +
    geom_pointrange(aes(color = method, ymin = l2$mean - l2$se, ymax = l2$mean + l2$se),
                    position = position_dodge(width = 0.4), fatten = 0.6, size = 0.8, show.legend = FALSE) +
    scale_x_discrete(labels = dataset_labels) +
    scale_y_continuous(limits = c(2.8, 6.8), breaks = c(3, 4, 5, 6)) +
    scale_color_manual(values = contrast_colors) +
    labs(y = "Prediction error ($L_2$)", 
         subtitle = paste0("\\textcolor{colorbrewerDarkOrange}{\\scalebox{1.3}{$\\bullet$}} GEARS vs.\n",
                           "\\textcolor{colorbrewerDarkPurple}{\\scalebox{1.3}{$\\bullet$}} LM with $\\matr{P}$ from GEARS")) +
    guides(x = guide_axis(angle = 90)) +
    theme(axis.title.x = element_blank(), plot.title.position = "plot")

comparison_plot_lpm <- res_metrics %>%
  filter(method  == "lpm_selftrained" |
           (dataset_name %in% c("adamson", "replogle_rpe1_essential") & method == "lpm_k562PertEmb") |
           (dataset_name %in% c("replogle_k562_essential") & method == "lpm_rpe1PertEmb")) %>%
  mutate(method = if_else(str_detect(method, "lpm_((k562)|(rpe1))PertEmb"), "lpm_pertEmb", method)) %>%
  filter(train != "train") %>%
  summarize(l2 = {
    tmp <- bootstrap(l2, mean, map_fun = map_dbl)
    tibble(mean = mean(tmp$value), se = sd(tmp$value))
  }, .by = c(method, dataset_name)) %>%
  mutate(method = factor(method, c("lpm_selftrained", "lpm_pertEmb"))) %>%
  ggplot(aes(x = dataset_name, y = l2$mean)) +
    geom_pointrange(aes(color = method, ymin = l2$mean - l2$se, ymax = l2$mean + l2$se),
                    position = position_dodge(width = 0.4), fatten = 0.6, size = 0.8, show.legend = FALSE) +
    scale_x_discrete(labels = dataset_labels) +
    scale_y_continuous(limits = c(2.8, 6.8), breaks = c(3, 4, 5, 6)) +
    scale_color_manual(values = contrast_colors) +  
    labs(y = "Prediction error ($L_2$)", 
         subtitle = paste0("\\textcolor{colorbrewerDarkOrange}{\\scalebox{1.3}{$\\bullet$}} LM vs.\n",
                           "\\textcolor{colorbrewerDarkPurple}{\\scalebox{1.3}{$\\bullet$}} LM with $\\matr{P}$ from Replogle")) +
    guides(x = guide_axis(angle = 90)) +
    theme(axis.title.x = element_blank(), plot.title.position = "plot")

comparison_plot_lpm2 <- res_metrics %>%
  filter(method %in% c("lpm_selftrained", "lpm_randomPertEmb")) %>%
  filter(train != "train") %>%
  summarize(l2 = {
    tmp <- bootstrap(l2, mean, map_fun = map_dbl)
    tibble(mean = mean(tmp$value), se = sd(tmp$value))
  }, .by = c(method, dataset_name)) %>%
  mutate(method = factor(method, c("lpm_selftrained", "lpm_randomPertEmb"))) %>%
  ggplot(aes(x = dataset_name, y = l2$mean)) +
    geom_pointrange(aes(color = method, ymin = l2$mean - l2$se, ymax = l2$mean + l2$se),
                    position = position_dodge(width = 0.4), fatten = 0.6, size = 0.8, show.legend = FALSE) +
    scale_x_discrete(labels = dataset_labels) +
    scale_y_continuous(limits = c(2.8, 6.8), breaks = c(3, 4, 5, 6)) +
    scale_color_manual(values = contrast_colors) +
    labs(y = "Prediction error ($L_2$)", 
         subtitle = paste0("\\textcolor{colorbrewerDarkOrange}{\\scalebox{1.3}{$\\bullet$}} LM vs.\n",
                           "\\textcolor{colorbrewerDarkPurple}{\\scalebox{1.3}{$\\bullet$}} LM with random $\\matr{P}$")) +
    guides(x = guide_axis(angle = 90)) +
    theme(axis.title.x = element_blank(), plot.title.position = "plot")


comparison_plot_scgpt
comparison_plot_scfoundation
comparison_plot_gears
comparison_plot_lpm
comparison_plot_lpm2
```   


```{r}
plot_assemble(
  add_text("(A) Single perturbation prediction error", x = 2.7, y = 1, fontsize = font_size, vjust = 1, fontface = "bold"),
  add_plot(main_pl, x = 0, y = 4, width = 100, height = 47.5),
  
  add_text("(B) Prediction error stratified by gene set size", x = 102, y = 1, fontsize = font_size, vjust = 1, fontface = "bold"),
  add_plot(strat_plot, x = 100, y = 4, width = 70, height = 45.5),
  
  add_text("(C) Plugging different embeddings into the linear model", x = 2.7, y = 54, fontsize = font_size, vjust = 1, fontface = "bold"),
  add_plot(comparison_plot_scgpt, x = 0, y = 58, width = 30, height = 42),
  add_plot(comparison_plot_scfoundation, x = 33, y = 58, width = 30, height = 42),
  add_plot(comparison_plot_gears, x = 68, y = 58, width = 30, height = 42),
  add_plot(comparison_plot_lpm,  x = 101, y = 58, width = 30, height = 42),
  add_plot(comparison_plot_lpm2, x = 134, y = 58, width = 30, height = 42),

  width = 170, height = 100, units = "mm", show_grid_lines = FALSE,
  latex_support = TRUE, filename = "../plots/single_perturbation_prediction.pdf"
)
```

# Session Info

```{r}
sessionInfo()
```


